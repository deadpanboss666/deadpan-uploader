"""
Uploader per YouTube basato SOLO su OAuth (client_secret.json + token.json).

Viene usato sia in locale che su GitHub Actions.
- In locale, se token.json non esiste, apre il flusso OAuth nel browser.
- Su GitHub Actions, token.json esiste giÃ  (lo ricostruiamo dai secret) e il codice
  usa solo il refresh token, senza aprire nessun browser.
"""

from __future__ import annotations

from pathlib import Path
from typing import List, Optional

from subtitles import generate_subtitles_txt_from_text

from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from googleapiclient.http import MediaFileUpload
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow

# Cartella src/
BASE_DIR = Path(__file__).resolve().parent
ROOT_DIR = BASE_DIR.parent

# File OAuth
CLIENT_SECRET_FILE = BASE_DIR / "client_secret.json"
TOKEN_FILE = BASE_DIR / "token.json"

# Scope necessario per upload su YouTube
SCOPES = ["https://www.googleapis.com/auth/youtube.upload"]


# ---------------------------------------------------------------------------
# AUTENTICAZIONE YOUTUBE (OAUTH)
# ---------------------------------------------------------------------------


def _get_oauth_credentials() -> Credentials:
    """Carica le credenziali OAuth da token.json, eventualmente le refresh-a."""
    creds: Optional[Credentials] = None

    if TOKEN_FILE.exists():
        creds = Credentials.from_authorized_user_file(str(TOKEN_FILE), SCOPES)

    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file(str(CLIENT_SECRET_FILE), SCOPES)
            creds = flow.run_local_server(port=0)

        TOKEN_FILE.write_text(creds.to_json(), encoding="utf-8")

    return creds


def _get_youtube_service():
    """Crea il client YouTube autenticato con OAuth."""
    creds = _get_oauth_credentials()
    return build("youtube", "v3", credentials=creds)


# ---------------------------------------------------------------------------
# CHECK FILE VIDEO PRIMA DELL'UPLOAD
# ---------------------------------------------------------------------------


def _check_video_file(video_path: str | Path) -> bool:
    """Controlla che il file video esista e non sia vuoto/corrotto."""
    p = Path(video_path)

    if not p.exists():
        print(f"[Monday] ERRORE: file video non trovato: {p}")
        return False

    size = p.stat().st_size
    print(f"[Monday] Video per upload: {p} (dimensione: {size} byte)")

    if size < 1024:
        print("[Monday] ERRORE: file video troppo piccolo / probabilmente corrotto.")
        return False

    return True


# ---------------------------------------------------------------------------
# UPLOAD VIDEO
# ---------------------------------------------------------------------------


def upload_video(
    video_path: str | Path,
    title: str,
    description: str,
    tags: Optional[List[str]] = None,
    privacy_status: str = "public",
) -> str:
    """Carica un video su YouTube e restituisce l'ID del video."""
    video_path = Path(video_path)

    if not _check_video_file(video_path):
        raise RuntimeError("[Monday] Upload annullato: file video non valido.")

    youtube = _get_youtube_service()

    safe_title = (str(title) if title is not None else "").strip() or "Deadpan Auto Test"
    safe_title = safe_title[:95]

    safe_description = (description or "").strip() or "Autogenerated short by Creator Automatico."

    safe_tags: List[str] = []
    if isinstance(tags, (list, tuple)):
        for t in tags:
            if not t:
                continue
            s = str(t).strip()
            if s:
                safe_tags.append(s[:30])

    print("Titolo che inviamo a YouTube:", repr(safe_title))

    body = {
        "snippet": {
            "title": safe_title,
            "description": safe_description,
            "tags": safe_tags,
            "categoryId": "27",
        },
        "status": {"privacyStatus": privacy_status},
    }

    media = MediaFileUpload(str(video_path), chunksize=-1, resumable=False)

    try:
        print("Inizio upload...")
        request = youtube.videos().insert(
            part="snippet,status",
            body=body,
            media_body=media,
        )
        response = request.execute()
        video_id = response["id"]
        print(f"âœ… Upload completato. ID video: {video_id}")
        return video_id
    except HttpError as e:
        msg = str(e)
        print(f"âŒ Errore durante l'upload: {msg}")

        if "uploadLimitExceeded" in msg:
            print(
                "[YouTube] Limite di upload raggiunto per questo account. "
                "La pipeline Ã¨ ok, ma YouTube al momento non accetta nuovi video."
            )
            return ""

        raise


# ---------------------------------------------------------------------------
# GENERAZIONE TESTO (SCRIPT) DEADPAN FILES â€” "VITA NATURAL DURANTE"
# ---------------------------------------------------------------------------


def generate_script():
    """
    Obiettivo: storie SEMPRE diverse, senza intervento umano:
    - spazio combinatorio enorme (procedurale)
    - 12+ strutture diverse (non template fisso)
    - dettagli variabili (nomi, luoghi, prove, contraddizioni, conseguenze)
    - output breve e ritmato (TTS + sottotitoli)
    """
    import hashlib
    import os
    import random
    import textwrap
    from datetime import datetime, timezone

    # Seed unico per ogni run (time + entropy). Non dipende dalla memoria tra run.
    stamp = datetime.now(timezone.utc).strftime("%Y%m%d%H%M%S")
    entropy = os.urandom(16).hex()
    seed_material = f"{stamp}-{entropy}-{os.getpid()}"
    seed = int(hashlib.sha256(seed_material.encode("utf-8")).hexdigest()[:16], 16)
    rng = random.Random(seed)

    # ----------------------------
    # VOCABOLARI (procedurali)
    # ----------------------------
    agencies = [
        "Records Division", "Missing Persons Unit", "Evidence Control", "Night Dispatch",
        "County Forensics", "Transit Police", "Hospital Security", "Incident Review Board",
        "Cold Case Taskforce", "Internal Affairs", "Property & Storage", "Audio Lab"
    ]

    place_types = [
        "motel", "train station", "hospital wing", "parking garage", "storage unit",
        "public library", "paper mill", "cinema", "subway platform", "riverside trail",
        "weather station", "county archive", "old courthouse", "service tunnel"
    ]
    place_adjs = [
        "shuttered", "abandoned", "flooded", "sealed", "renovated", "quiet", "condemned",
        "temporary", "off-limits", "unfinished", "unmarked", "windowless", "underground"
    ]
    neighborhoods = [
        "north side", "east district", "old town", "industrial strip", "coastal road",
        "rural outskirts", "downtown grid", "hillside blocks", "harbor line", "factory row"
    ]

    evidence_items = [
        "cassette tape", "burned CD", "memory card", "disposable camera", "keycard",
        "voicemail transcript", "radio log", "lab report", "polaroid", "door access record",
        "evidence bag", "handwritten note", "pager", "receipt", "security export"
    ]
    evidence_verbs = [
        "was tagged", "was sealed", "was logged", "was duplicated", "was misfiled",
        "was re-labeled", "was re-sealed", "was transferred", "was archived", "was destroyed"
    ]

    anomalies = [
        "a shadow with no source", "a timestamp that goes backwards", "breathing behind the mic",
        "footsteps approaching the recorder", "a second voice that never speaks again",
        "a reflection that shows another room", "a door that opens on a closed corridor",
        "a name that shouldnâ€™t exist", "a camera angle from impossible distance",
        "a fingerprint set that matches itself", "a file created tomorrow", "a call from a dead number"
    ]

    contradictions = [
        "the report says one thing, the evidence says another",
        "the timeline breaks in one place",
        "every witness agreesâ€”on the wrong detail",
        "the photo doesnâ€™t match the room",
        "the audio contains no voices, only proximity",
        "the access log shows entry, the camera shows nobody",
        "the signature belongs to someone not on payroll",
        "the file hash matches an older case, perfectly",
        "the printout is dated next week",
        "the metadata lists a device that was never manufactured"
    ]

    consequences = [
        "the officer requested a transfer at sunrise",
        "the guard quit without notice",
        "the family received letters addressed to the missing person",
        "the evidence room was re-locked and re-numbered",
        "the entire shift was reassigned",
        "the archive clerk stopped coming to work",
        "the station closed early, once, and never explained why",
        "the case number was sealed againâ€”under a new label",
        "the tape was returned with fresh fingerprints",
        "the report vanished from the system overnight"
    ]

    tones = [
        "clinical", "confessional", "dispatch", "memo", "transcript", "casefile",
        "foundfootage", "forensics", "redacted", "afteraction", "catalog", "witness"
    ]

    ctas = [
        "Follow Deadpan Files. Another box is waiting.",
        "Follow Deadpan Files. The next file has your city in it.",
        "Follow Deadpan Files. This wasnâ€™t the last recording.",
        "Follow Deadpan Files. The next case starts with a name youâ€™ll recognize.",
        "Follow Deadpan Files. Weâ€™re opening the next drawer tonight.",
        "Follow Deadpan Files for more archived horror."
    ]

    # nomi procedurali (combinazione enorme)
    first_names = [
        "Evan", "Noah", "Mason", "Liam", "Caleb", "Lucas", "Aiden", "Owen", "Miles", "Nate",
        "Hannah", "Maya", "Ava", "Nina", "Claire", "Elena", "Lena", "Sofia", "Iris", "June"
    ]
    last_names = [
        "Harper", "Caldwell", "Reyes", "Bennett", "Hughes", "Moreno", "Sullivan", "Park",
        "Fletcher", "Sinclair", "Rowe", "Keller", "Vaughn", "Pierce", "Donovan", "Hale"
    ]

    def pick(pool: list[str]) -> str:
        return rng.choice(pool)

    def make_case_code() -> str:
        return f"{rng.randint(1, 99):02d}-{rng.randint(1, 28):02d}-{rng.randint(10, 99)}"

    def make_year() -> int:
        return rng.choice([1987, 1991, 1994, 1998, 2001, 2006, 2011, 2016, 2019, 2021])

    def make_time() -> str:
        return f"{rng.randint(0, 4):02d}:{rng.choice([13, 17, 22, 31, 44, 58]):02d}"

    def make_place() -> str:
        return f"a {pick(place_adjs)} {pick(place_types)} on the {pick(neighborhoods)}"

    def make_person() -> str:
        return f"{pick(first_names)} {pick(last_names)}"

    def tighten(s: str, max_len: int = 140) -> str:
        s = " ".join(s.replace("â€”", ". ").replace("â€¦", "...").split())
        if len(s) <= max_len:
            return s
        return textwrap.shorten(s, width=max_len, placeholder="...")

    # ----------------------------
    # COSTRUZIONE â€œFATTIâ€
    # ----------------------------
    agency = pick(agencies)
    case_code = make_case_code()
    year = make_year()
    t = make_time()
    place = make_place()
    item = pick(evidence_items)
    anomaly = pick(anomalies)
    contradiction = pick(contradictions)
    consequence = pick(consequences)
    person = make_person()

    # Hook: 2 frasi, sempre variabili
    hook_patterns = [
        "Case file {code} was sealed in {year}. It still keeps changing.",
        "They archived {code} under {agency}. The metadata rewrote itself.",
        "The call log says {t}. The recording begins before we answered.",
        "We found a {item} in {place}. It was already labeled with our case number.",
        "The report lists {person} as a witness. {person} died in {year}.",
        "Footage from {place} is cleanâ€”until the last ten seconds."
    ]
    hook = tighten(pick(hook_patterns).format(
        code=case_code, year=year, agency=agency, t=t, item=item, place=place, person=person
    ), 170)

    # â€œEvidence beatâ€ e â€œEscalation beatâ€
    evidence_patterns = [
        "The {item} {verb} and stored under {agency}. Then it moved shelves by itself.",
        "Every frame shows {anomaly}. The room has no object that could cast it.",
        "The access log shows a keycard swipe at {t}. The camera shows nobody entering.",
        "The audio contains only {anomaly}. No words. No voices. Just proximity.",
        "The phone placed seven calls after the official time of death. Same number. Same ring."
    ]
    evidence = tighten(pick(evidence_patterns).format(
        item=item, verb=pick(evidence_verbs), agency=agency, anomaly=anomaly, t=t
    ), 190)

    escalation_patterns = [
        "We checked again. {contradiction}.",
        "Forensics flagged the file. {contradiction}.",
        "When we enhanced the audio, the noise shaped into a second rhythm.",
        "The timeline doesnâ€™t drift. It snaps.",
        "The case appears in another archiveâ€”same hash, different year.",
    ]
    escalation = tighten(pick(escalation_patterns).format(contradiction=contradiction), 170)

    # Twist + ending
    twist_patterns = [
        "Then the evidence did something it canâ€™t do: it addressed us by name.",
        "The last frame shows the victim looking into the lensâ€”filmed from behind.",
        "The whisper wasnâ€™t a word. It was a dateâ€”tomorrow.",
        "The calls werenâ€™t from the victim. They were from the evidence room.",
        "The signature belongs to an officer who never existed on payroll.",
        "The fileâ€™s creation date is tomorrow. We verified the server clock.",
    ]
    twist = tighten(pick(twist_patterns), 170)

    end_patterns = [
        "At sunrise, {consequence}.",
        "By morning, {consequence}.",
        "After we logged it, {consequence}.",
        "We sealed the drawer again. Two days later, the label changed.",
        "We requested the original export. What we received was shorterâ€”missing one second."
    ]
    ending = tighten(pick(end_patterns).format(consequence=consequence), 190)

    cta = pick(ctas)

    # ----------------------------
    # 12 STRUTTURE DIVERSE
    # ----------------------------
    formats = []

    formats.append(f"{hook} {evidence} {escalation} {twist} {ending} {cta}")

    formats.append(
        f"Night dispatch log â€” {agency}. {hook} "
        f"Unit reports activity at {place}. {evidence} {twist} {ending} {cta}"
    )

    formats.append(
        f"Transcript excerpt â€” case {case_code}. {hook} "
        f"{evidence} {escalation} {twist} {cta}"
    )

    formats.append(
        f"Archived memo from {agency}. Subject: {place}. "
        f"{hook} {evidence} {ending} {cta}"
    )

    formats.append(
        f"Found footage note. Seized item: {item}. Location: {place}. "
        f"{hook} {evidence} {twist} {cta}"
    )

    formats.append(
        f"Evidence catalog entry {case_code}. {item} â€” status: sealed. "
        f"{hook} {escalation} {twist} {ending} {cta}"
    )

    formats.append(
        f"Witness statement: {person}. {hook} "
        f"{evidence} {twist} {ending} {cta}"
    )

    formats.append(
        f"Forensics addendum. {hook} "
        f"Anomaly observed: {anomaly}. {escalation} {twist} {cta}"
    )

    formats.append(
        f"Redacted report. {hook} "
        f"{evidence} [REDACTED]. {twist} {ending} {cta}"
    )

    formats.append(
        f"After-action summary. {hook} "
        f"{escalation} Outcome: {ending} {cta}"
    )

    formats.append(
        f"Audio lab note. {hook} "
        f"Source artifact: {item}. {evidence} {twist} {cta}"
    )

    formats.append(
        f"Cold case brief. {hook} "
        f"Primary contradiction: {contradiction}. {twist} {ending} {cta}"
    )

    # Scegli formato e â€œripulisciâ€ per TTS
    script = pick(formats)
    script = " ".join(script.replace("â€”", ". ").replace("â€¦", "...").split()).strip()

    # ----------------------------
    # TITOLI: tantissimi pattern + variabili
    # ----------------------------
    title_patterns = [
        "The {item} That Rewrote The Case",
        "The Case File That Kept Changing",
        "The Footage From {place_type}",
        "The Call From A Dead Number",
        "The Evidence Room Incident",
        "The Transcript With One Missing Second",
        "The Night Dispatch Log They Wonâ€™t Explain",
        "The Timestamp That Went Backwards",
        "The Report Signed By Nobody",
        "The Tape That Knew Tomorrow"
    ]
    title = pick(title_patterns).format(
        item=item.title(),
        place_type=pick(place_types).title(),
    )
    title = tighten(title, 88)

    # Descrizione: breve, â€œserialeâ€, monetizzabile
    description = "\n".join([
        hook,
        evidence,
        twist,
        "",
        "Deadpan Files â€” short true crime / horror case files.",
        "New files drop automatically. Follow for the next report."
    ])

    # Tags: variabili, ma pulite
    base_tags = [
        "deadpan files", "true crime", "horror story", "mystery", "unexplained", "shorts",
        "case file", "found footage", "evidence", "dispatch log", "creepy", "archived"
    ]
    # aggiungi 2-3 tag dinamici (sempre diversi)
    dynamic_tags = [
        item.lower(),
        pick(place_types),
        pick(["cctv", "voicemail", "audio tape", "cold case", "case report", "evidence room"]),
    ]
    tags = list(dict.fromkeys(base_tags + dynamic_tags))[:20]

    return script, title, description, tags


# ---------------------------------------------------------------------------
# SINTESI VOCALE (legacy) â€” lasciata per compatibilitÃ 
# ---------------------------------------------------------------------------


def synth_voice(text, output_path):
    """
    Legacy: gTTS a chunk -> WAV 48 kHz mono + subtitles.txt (legacy).
    La pipeline nuova usa tts_timestamps.py.
    """
    from pathlib import Path as _Path
    from gtts import gTTS
    import subprocess as _subprocess
    import textwrap as _textwrap

    text = (text or "").strip()
    if not text:
        raise ValueError("Testo vuoto passato a synth_voice")

    output_path = _Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    subtitles_txt_path = _Path("videos_to_upload") / "subtitles.txt"
    subtitles_txt_path.parent.mkdir(parents=True, exist_ok=True)
    generate_subtitles_txt_from_text(raw_text=text, subtitles_txt_path=subtitles_txt_path)

    temp = text.replace("?", "?.").replace("!", "!.")
    sentences = [s.strip() for s in temp.split(".") if s.strip()]
    if not sentences:
        sentences = [text]

    max_chars = 180
    chunks: list[str] = []
    current = ""

    for s in sentences:
        if len(current) + len(s) + 1 <= max_chars:
            current = f"{current} {s}".strip() if current else s
        else:
            if current:
                chunks.append(current)
            if len(s) > max_chars:
                parts = _textwrap.wrap(s, max_chars)
                chunks.extend(parts)
                current = ""
            else:
                current = s

    if current:
        chunks.append(current)

    if not chunks:
        chunks = [text]

    print(f"[Monday/voice] Numero chunk TTS: {len(chunks)}")

    tmp_dir = output_path.parent
    part_paths: list[_Path] = []

    for idx, chunk in enumerate(chunks, start=1):
        part_mp3 = tmp_dir / f"voice_part_{idx:02d}.mp3"
        print(f"[Monday/voice] Genero chunk {idx}/{len(chunks)} (len={len(chunk)})...")
        tts = gTTS(text=chunk, lang="en", slow=False)
        tts.save(str(part_mp3))
        part_paths.append(part_mp3)

    concat_list = tmp_dir / "voice_concat.txt"
    concat_list.write_text("".join(f"file '{p.as_posix()}'\n" for p in part_paths), encoding="utf-8")

    tmp_mp3 = output_path.with_suffix(".mp3")

    cmd_concat = [
        "ffmpeg", "-y",
        "-f", "concat", "-safe", "0",
        "-i", str(concat_list),
        "-c", "copy",
        str(tmp_mp3),
    ]
    print("[Monday/voice] Concateno i chunk audio con ffmpeg...")
    _subprocess.run(cmd_concat, check=True)

    cmd_wav = [
        "ffmpeg", "-y",
        "-i", str(tmp_mp3),
        "-ac", "1",
        "-ar", "48000",
        str(output_path),
    ]
    print("[Monday/voice] Converto l'audio in WAV 48 kHz mono...")
    _subprocess.run(cmd_wav, check=True)

    for p in part_paths:
        try:
            p.unlink()
        except FileNotFoundError:
            pass

    try:
        concat_list.unlink()
    except FileNotFoundError:
        pass

    try:
        tmp_mp3.unlink()
    except FileNotFoundError:
        pass

    print(f"[Monday/voice] Audio finale pronto: {output_path}")


if __name__ == "__main__":
    dummy_path = BASE_DIR / "video.mp4"
    if dummy_path.exists():
        upload_video(
            video_path=dummy_path,
            title="Test upload YouTube (OAuth only)",
            description="Upload di test eseguito da uploader.py #shorts",
            tags=["test", "automation"],
            privacy_status="public",
        )
    else:
        print(f"Nessun file di test trovato: {dummy_path}")


